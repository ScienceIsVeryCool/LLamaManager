{
  "metadata": {
    "name": "Competitive Cellular Automata Development with Testing",
    "version": "3.0",
    "description": "Two junior developers compete to create the best cellular automata simulation with iterative feedback and execution testing"
  },
  
  "agents": {
    "optimistic": {
      "model": "gemma3:4b",
      "temperature": 0.8,
      "personality": "You are an enthusiastic junior developer who loves experimenting with creative visual effects. You tend to favor colorful, dynamic solutions and enjoy using cutting-edge libraries. You write Python code with lots of comments explaining your excitement about each feature. You believe in 'go big or go home' and love adding extra visual flair.",
      "contextType": "rolling"
    },
    "pragmatic": {
      "model": "gemma3:4b",
      "temperature": 0.6,
      "personality": "You are a methodical junior developer who values clean, efficient code. You prefer well-tested libraries and established patterns. You write Python code with a focus on performance and maintainability. You believe in 'keep it simple, stupid' and optimize for clarity and speed. You're skeptical of unnecessary features.",
      "contextType": "rolling"
    },
    "reviewer": {
      "model": "gemma3:4b",
      "temperature": 0.3,
      "personality": "You are a Senior Engineer evaluating competing implementations. You value both creativity and practicality. Be direct about strengths and weaknesses. Consider performance, visual appeal, code quality, and how well the solution meets requirements. Pick a winner but give balanced feedback to both developers.",
      "contextType": "rolling"
    },
    "tester": {
      "model": "gemma3:4b",
      "temperature": 0.4,
      "personality": "You are a QA Engineer who tests code execution. You analyze runtime output, error messages, and performance characteristics. You identify bugs, crashes, performance issues, and provide practical feedback on what actually works vs what was intended. You're detail-oriented about execution problems.",
      "contextType": "clean"
    }
  },
  
  "actions": {
    "initialDesign": {
      "prompt": "Design a Python cellular automata simulation with these requirements:\n\n1. Must use matplotlib or similar for visualization\n2. Should leverage numpy or other libraries for performance\n3. Must run indefinitely (no stop condition except extinction)\n4. Should show interesting emergent behavior\n5. Include real-time visualization that updates smoothly\n6. Initial state should lead to interesting evolution\n\nProvide complete, runnable code. Focus on {{1}}."
    },
    "compareImplementations": {
      "prompt": "Compare these two cellular automata implementations:\n\n=== OPTIMISTIC DEVELOPER'S CODE ===\n{{1}}\n\n=== PRAGMATIC DEVELOPER'S CODE ===\n{{2}}\n\nEvaluate based on:\n1. Visual appeal and user experience\n2. Performance and efficiency\n3. Code quality and maintainability\n4. Meeting the requirement of running indefinitely\n5. Emergent behavior complexity\n\nPick a winner and explain why. Give specific feedback for each developer on what they did well and what needs improvement."
    },
    "provideIterationGuidance": {
      "prompt": "Based on your comparison, provide specific guidance for the next iteration:\n\n1. What should the optimistic developer focus on improving?\n2. What should the pragmatic developer focus on improving?\n3. What specific features or changes would make each implementation better?\n4. Are there ideas from one implementation that the other should consider?\n\nBe specific and actionable. This is iteration {{1}} of 3."
    },
    "improveBasedOnFeedback": {
      "prompt": "Your previous implementation received this feedback:\n\n{{1}}\n\nImprove your cellular automata simulation addressing the specific points raised. Maintain your coding style but incorporate the suggestions. Remember:\n- Must run indefinitely (only stop on extinction)\n- Focus on smooth visualization\n- Show interesting emergent patterns\n\nProvide the complete improved implementation."
    },
    "analyzeExecution": {
      "prompt": "Analyze this program execution output:\n\n{{1}}\n\nFocus on:\n1. Did the program run successfully or crash?\n2. What errors or warnings occurred?\n3. How long did it run before stopping?\n4. Any performance issues or bottlenecks?\n5. Does the output suggest the simulation is working as intended?\n6. What runtime issues need to be addressed?\n\nProvide specific technical feedback on the execution quality."
    },
    "combineExecutionFeedback": {
      "prompt": "Combine execution test results with code review:\n\n=== CODE REVIEW ===\n{{1}}\n\n=== OPTIMISTIC EXECUTION RESULTS ===\n{{2}}\n\n=== PRAGMATIC EXECUTION RESULTS ===\n{{3}}\n\nProvide comprehensive feedback that considers both code quality AND actual runtime performance. Which implementation actually works better in practice? What are the real-world differences between the approaches?"
    },
    "finalJudgment": {
      "prompt": "This is the final comparison. Evaluate the latest implementations:\n\n=== OPTIMISTIC DEVELOPER'S FINAL CODE ===\n{{1}}\n\n=== PRAGMATIC DEVELOPER'S FINAL CODE ===\n{{2}}\n\nProvide:\n1. Final winner and detailed reasoning\n2. What each developer did best throughout the iterations\n3. Key lessons learned from this competition\n4. Which approach would you recommend for production use and why"
    },
    "buildCompetitionReport": {
      "prompt": "Create a comprehensive competition report with the following sections:\n\n# Competition Results and Analysis\n\n{{1}}\n\n## Iteration History\n\n### Iteration 1\n{{2}}\n\n{{3}}\n\n### Iteration 2\n{{4}}\n\n{{5}}\n\n### Iteration 3\n{{6}}\n\n{{7}}\n\n### Iteration 4\n{{8}}\n\n{{9}}\n\nFormat this as a proper markdown document."
    }
  },
  
  "workflow": [
    {
      "action": "initialDesign",
      "agent": "optimistic",
      "inputs": ["maximum visual impact with colorful, dynamic effects"],
      "output": "optimistic_v1.md"
    },
    {
      "action": "initialDesign",
      "agent": "pragmatic",
      "inputs": ["clean, efficient implementation with optimal performance"],
      "output": "pragmatic_v1.md"
    },
    {
      "action": "loop",
      "iterations": 3,
      "steps": [
        {
          "action": "compareImplementations",
          "agent": "reviewer",
          "inputs": ["optimistic_v{{iteration}}.md", "pragmatic_v{{iteration}}.md"],
          "output": "comparison_{{iteration}}.md"
        },
        {
          "action": "improveBasedOnFeedback",
          "agent": "optimistic",
          "inputs": ["Extract just the python code from the implementation"],
          "output": "optimistic_v{{iteration}}.py",
          "format": "python"
        },
        {
          "action": "improveBasedOnFeedback",
          "agent": "pragmatic",
          "inputs": ["Extract just the python code from the implementation"],
          "output": "pragmatic_v{{iteration}}.py",
          "format": "python"
        },
        {
          "action": "run_python",
          "inputs": ["optimistic_v{{iteration}}.py"],
          "output": "optimistic_execution_{{iteration}}.log"
        },
        {
          "action": "run_python",
          "inputs": ["pragmatic_v{{iteration}}.py"],
          "output": "pragmatic_execution_{{iteration}}.log"
        },
        {
          "action": "analyzeExecution",
          "agent": "tester",
          "inputs": ["optimistic_execution_{{iteration}}.log"],
          "output": "optimistic_execution_analysis_{{iteration}}.md"
        },
        {
          "action": "analyzeExecution",
          "agent": "tester",
          "inputs": ["pragmatic_execution_{{iteration}}.log"],
          "output": "pragmatic_execution_analysis_{{iteration}}.md"
        },
        {
          "action": "combineExecutionFeedback",
          "agent": "reviewer",
          "inputs": [
            "comparison_{{iteration}}.md",
            "optimistic_execution_analysis_{{iteration}}.md",
            "pragmatic_execution_analysis_{{iteration}}.md"
          ],
          "output": "combined_feedback_{{iteration}}.md"
        },
        {
          "action": "provideIterationGuidance",
          "agent": "reviewer",
          "inputs": ["{{iteration}}"],
          "output": "guidance_{{iteration}}.md"
        },
        {
          "action": "improveBasedOnFeedback",
          "agent": "optimistic",
          "inputs": ["combined_feedback_{{iteration}}.md"],
          "output": "optimistic_v{{iteration}}_improved.md"
        },
        {
          "action": "improveBasedOnFeedback",
          "agent": "pragmatic",
          "inputs": ["combined_feedback_{{iteration}}.md"],
          "output": "pragmatic_v{{iteration}}_improved.md"
        },
        {
          "action": "clearContext",
          "agent": "reviewer"
        },
        {
          "action": "clearContext",
          "agent": "tester"
        }
      ]
    },
    {
      "action": "finalJudgment",
      "agent": "reviewer",
      "inputs": ["optimistic_v4_improved.md", "pragmatic_v4_improved.md"],
      "output": "final_judgment.md"
    },
    {
      "action": "buildCompetitionReport",
      "agent": "reviewer",
      "inputs": [
        "final_judgment.md",
        "comparison_1.md",
        "combined_feedback_1.md",
        "comparison_2.md",
        "combined_feedback_2.md",
        "comparison_3.md",
        "combined_feedback_3.md",
        "comparison_4.md",
        "combined_feedback_4.md"
      ],
      "output": "competition_analysis.md"
    },
    {
      "action": "improveBasedOnFeedback",
      "agent": "optimistic",
      "inputs": ["competition_analysis.md"],
      "output": "cellular_automata_optimistic_final.py",
      "format": "python"
    },
    {
      "action": "improveBasedOnFeedback",
      "agent": "pragmatic",
      "inputs": ["competition_analysis.md"],
      "output": "cellular_automata_pragmatic_final.py",
      "format": "python"
    },
    {
      "action": "run_python",
      "inputs": ["cellular_automata_optimistic_final.py"],
      "output": "final_optimistic_execution.log"
    },
    {
      "action": "run_python",
      "inputs": ["cellular_automata_pragmatic_final.py"],
      "output": "final_pragmatic_execution.log"
    },
    {
      "action": "analyzeExecution",
      "agent": "tester",
      "inputs": ["final_optimistic_execution.log"],
      "output": "final_optimistic_analysis.md"
    },
    {
      "action": "analyzeExecution",
      "agent": "tester",
      "inputs": ["final_pragmatic_execution.log"],
      "output": "final_pragmatic_analysis.md"
    },
    {
      "action": "combineExecutionFeedback",
      "agent": "reviewer",
      "inputs": [
        "final_judgment.md",
        "final_optimistic_analysis.md",
        "final_pragmatic_analysis.md"
      ],
      "output": "final_execution_comparison.md"
    }
  ],
  
  "config": {
    "logLevel": "info",
    "outputDirectory": "./Acellular_competition_with_testing_new1",
    "queryTimeout": 3000,
    "maxContextTokens": 8000
  }
}